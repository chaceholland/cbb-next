#!/bin/bash
# Installation script for automated ESPN scraper

set -e

echo "ğŸ”§ Installing Automated ESPN Scraper"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# Get the directory where this script is located
SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
cd "$SCRIPT_DIR"

# Step 1: Create log directory
echo ""
echo "1ï¸âƒ£  Creating log directory..."
mkdir -p "$SCRIPT_DIR/scraper-logs"
echo "âœ… Created scraper-logs/"

# Step 2: Make scripts executable
echo ""
echo "2ï¸âƒ£  Making scripts executable..."
chmod +x schedule-scraper.sh
chmod +x auto-scrape-participation.mjs
echo "âœ… Scripts are now executable"

# Step 3: Test the scraper
echo ""
echo "3ï¸âƒ£  Testing scraper (will check 3 games)..."
node auto-scrape-participation.mjs --days 7 --max 3 --quiet
TEST_EXIT=$?

if [ $TEST_EXIT -eq 0 ]; then
  echo "âœ… Scraper test successful"
else
  echo "âš ï¸  Scraper test completed with warnings (this is normal if no data available yet)"
fi

# Step 4: Set up database tracking (requires manual SQL execution)
echo ""
echo "4ï¸âƒ£  Database setup required..."
echo "âš ï¸  Manual step needed: Run the SQL migration"
echo ""
echo "   Option A - Using Supabase Dashboard:"
echo "   1. Go to: https://supabase.com/dashboard"
echo "   2. Select your project"
echo "   3. Go to SQL Editor"
echo "   4. Copy contents of: add-scrape-tracking.sql"
echo "   5. Run the SQL"
echo ""
echo "   Option B - Using psql (if you have database URL):"
echo "   psql \$DATABASE_URL < add-scrape-tracking.sql"
echo ""
read -p "Press Enter after you've run the SQL migration (or press Ctrl+C to skip)..."

# Step 5: Install LaunchAgent (macOS only)
if [[ "$OSTYPE" == "darwin"* ]]; then
  echo ""
  echo "5ï¸âƒ£  Installing LaunchAgent (macOS)..."

  PLIST_SRC="$SCRIPT_DIR/com.cbb.scraper.plist"
  PLIST_DST="$HOME/Library/LaunchAgents/com.cbb.scraper.plist"

  # Unload existing agent if present
  if [ -f "$PLIST_DST" ]; then
    echo "Unloading existing agent..."
    launchctl unload "$PLIST_DST" 2>/dev/null || true
  fi

  # Copy plist
  cp "$PLIST_SRC" "$PLIST_DST"
  echo "âœ… Copied plist to ~/Library/LaunchAgents/"

  # Load the agent
  launchctl load "$PLIST_DST"
  echo "âœ… LaunchAgent loaded"

  # Start immediately
  launchctl start com.cbb.scraper
  echo "âœ… Scraper started"

  echo ""
  echo "ğŸ“‹ LaunchAgent Status:"
  launchctl list | grep cbb.scraper || echo "  (Agent is configured)"

else
  echo ""
  echo "5ï¸âƒ£  Detected non-macOS system"
  echo "Setting up cron job instead..."

  # Check if cron job already exists
  if crontab -l 2>/dev/null | grep -q "schedule-scraper.sh"; then
    echo "âš ï¸  Cron job already exists"
  else
    # Add cron job
    (crontab -l 2>/dev/null; echo "0 */6 * * * $SCRIPT_DIR/schedule-scraper.sh") | crontab -
    echo "âœ… Cron job added (runs every 6 hours)"
  fi
fi

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "âœ… Installation complete!"
echo ""
echo "ğŸ“Š What happens next:"
echo "  â€¢ Scraper runs every 6 hours automatically"
echo "  â€¢ Checks ESPN for pitcher participation data"
echo "  â€¢ Updates database when data is found"
echo "  â€¢ Logs results to: $SCRIPT_DIR/scraper-logs/"
echo ""
echo "ğŸ” Monitor progress:"
echo "  tail -f $SCRIPT_DIR/scraper-logs/scraper.log"
echo ""
echo "ğŸ›   Manage the service:"
if [[ "$OSTYPE" == "darwin"* ]]; then
  echo "  launchctl start com.cbb.scraper    # Start now"
  echo "  launchctl stop com.cbb.scraper     # Stop"
  echo "  launchctl unload ~/Library/LaunchAgents/com.cbb.scraper.plist  # Disable"
else
  echo "  crontab -e                         # Edit schedule"
  echo "  crontab -l                         # View current jobs"
fi
echo ""
